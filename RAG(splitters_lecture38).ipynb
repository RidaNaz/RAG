{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1yyrp2J0N99jdNu2E6yQjlQX3GamD5iji",
      "authorship_tag": "ABX9TyPR62FWDsIBTvTUpw+VOKjQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RidaNaz/RAG/blob/main/RAG(splitters_lecture38).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Types of Splitters**"
      ],
      "metadata": {
        "id": "q0PJDTl8uay-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.   **Recursive Splitters**\n",
        "\n",
        "\n",
        "*   RecursiveCharacterTextSplitter\n",
        "*   RecursiveJsonSplitter"
      ],
      "metadata": {
        "id": "F3aZLwms1NHf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2ZbKQyrZTps"
      },
      "outputs": [],
      "source": [
        "!pip install openai langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import sys\n",
        "sys.path.append('../..')"
      ],
      "metadata": {
        "id": "I0oBdl7pZf3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing the Packages for Splitters**"
      ],
      "metadata": {
        "id": "ndAILX9ywbb3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter"
      ],
      "metadata": {
        "id": "NWGYcK48aM33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining the Chunk Size**"
      ],
      "metadata": {
        "id": "9rTRe_QzwqF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# do some experiments with diffrent chunk size and overlap\n",
        "chunk_size = 26\n",
        "chunk_overlap = 4"
      ],
      "metadata": {
        "id": "JtFhD4kMacJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parameters in Splitters**"
      ],
      "metadata": {
        "id": "xnQnhp6dw1j9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = chunk_size,\n",
        "    chunk_overlap = chunk_overlap\n",
        ")\n",
        "\n",
        "c_splitter = CharacterTextSplitter(\n",
        "    chunk_size = chunk_size,\n",
        "    chunk_overlap = chunk_overlap\n",
        ")"
      ],
      "metadata": {
        "id": "hV_Te6z0atYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitter Example: 1\n",
        "\n"
      ],
      "metadata": {
        "id": "rjno4zsLxGDQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = \"abcdefghijklmnopqrstuvwxyz\""
      ],
      "metadata": {
        "id": "slk32pNncPyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text1"
      ],
      "metadata": {
        "id": "Na9gpsi1cZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r_splitter.split_text(text1)"
      ],
      "metadata": {
        "id": "j7p0RpVKcdZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c_splitter.split_text(text1)"
      ],
      "metadata": {
        "id": "9h9jlgtdctO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitter Example: 2"
      ],
      "metadata": {
        "id": "ZrQ7FvAdxNdu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text2 = \"abcdefghijklmnopqrstuvwxyzajhbvjhscdj\""
      ],
      "metadata": {
        "id": "PXjZpr8xcwvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text2"
      ],
      "metadata": {
        "id": "v9ePmus9dC9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r_splitter.split_text(text2)"
      ],
      "metadata": {
        "id": "hxftDUncdJeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c_splitter.split_text(text2)"
      ],
      "metadata": {
        "id": "EJCqWZvHdKKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SpacyTextSplitter**"
      ],
      "metadata": {
        "id": "N_ZgEz2ExVjM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade --quiet langchain-text-splitters tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgHelwjfdZyF",
        "outputId": "a2390014-d62b-44e6-eee8-55daf92dcc0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/1.1 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t= \"LangChain is a framework designed to facilitate the development of applications that leverage large language models (LLMs). It provides tools, components, and interfaces to help developers build more sophisticated and context-aware language model applications.\""
      ],
      "metadata": {
        "id": "XnY2-rXued0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade --quiet spacy"
      ],
      "metadata": {
        "id": "tOttjDrGdyWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import SpacyTextSplitter\n",
        "\n",
        "text_splitter = SpacyTextSplitter(chunk_size=10, chunk_overlap=5)\n",
        "texts = text_splitter.split_text(t)"
      ],
      "metadata": {
        "id": "uZexoXKud48w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts[0]"
      ],
      "metadata": {
        "id": "OVGPyM0sexd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PDF Loading & Splitting**"
      ],
      "metadata": {
        "id": "m4cVry1CxfIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf langchain_community"
      ],
      "metadata": {
        "id": "gEaNt0ESfGRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "loader = PyPDFLoader(\"/content/Tax Card- Tax Year 2025 -AHK.pdf\")\n",
        "pages = loader.load_and_split()"
      ],
      "metadata": {
        "id": "XuNzpSe2frN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(pages)"
      ],
      "metadata": {
        "id": "3yQT6_nVhr8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_list=[]\n",
        "for page in pages:\n",
        "  chunks = r_splitter.split_text(page.page_content)\n",
        "  for chunk in chunks:\n",
        "    chunk_list.append(chunk)\n",
        "print(len(chunk_list))"
      ],
      "metadata": {
        "id": "GYSxfFwVhvsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_list[200]"
      ],
      "metadata": {
        "id": "u8ETTPvci8gD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Semantic Splitters**\n",
        "\n",
        "Splits the text based on semantic similarity.\n",
        "\n",
        "At a high level, this splits into sentences, then groups into groups of 3 sentences, and then merges one that are similar in the embedding space."
      ],
      "metadata": {
        "id": "OZqvjpkn0obY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_experimental"
      ],
      "metadata": {
        "id": "sg-8MzlvqdAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_experimental.text_splitter import SemanticChunker"
      ],
      "metadata": {
        "id": "pHRhTLYAq0IQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet langchain_experimental langchain_openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwHqliYjrENq",
        "outputId": "b3e74d4d-451c-4a9b-fc24-8b653c5230e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/52.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = SemanticChunker(\n",
        "    embed_model, breakpoint_threshold_type= \"percentile\"\n",
        "    3\n",
        ")"
      ],
      "metadata": {
        "id": "EfhFCuWxrNpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = \"LangChain is a framework designed to facilitate the development of applications that leverage large language models (LLMs). It provides tools, components, and interfaces to help developers build more sophisticated and context-aware language model applications. Integration with LLMs:Purpose: LangChain simplifies the process of integrating large language models, like OpenAI's GPT, into your applications. It provides an abstraction layer that makes it easier to work with these models, whether you're generating text, answering questions, or performing more complex tasks.\""
      ],
      "metadata": {
        "id": "KonZhxeTswCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "semantic_splits = text_splitter.split_text(t)"
      ],
      "metadata": {
        "id": "mqTgvqoCszWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(semantic_splits)"
      ],
      "metadata": {
        "id": "cFmEGA5itB2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Embeddings**\n",
        "\n",
        "Embeddings are type of dense vector representation used to capture the semantic meaning of words, phrases, sentences, or other types of data.\n",
        "\n",
        "They are widely used in Natural Language Processing and other fields of machine learning to transform categorical data into numerical form, which is more suitable for computational models."
      ],
      "metadata": {
        "id": "zNjhKUAQxsUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers langchain_huggingface"
      ],
      "metadata": {
        "id": "vd47gC_mk3fA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings"
      ],
      "metadata": {
        "id": "TuIpwrHjj99j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_model = HuggingFaceEmbeddings(model_name='BAAI/bge-small-en-v1.5')"
      ],
      "metadata": {
        "id": "5e-EDM8-ln82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generate Embeddings**"
      ],
      "metadata": {
        "id": "T3U7d8Ks0K8S"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aIV2fvVi0OCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed = embed_model.embed_query(\"How are You?\")"
      ],
      "metadata": {
        "id": "VLIhDNYfl70Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(embed)"
      ],
      "metadata": {
        "id": "2ndv7UNZmN4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed"
      ],
      "metadata": {
        "id": "QKTm7-lTmVCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb = embed_model.embed_query(chunk_list[3])"
      ],
      "metadata": {
        "id": "eUy0Bvt_mYRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(emb)"
      ],
      "metadata": {
        "id": "EwpnTMFmmktW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb"
      ],
      "metadata": {
        "id": "peu3dxWtmn4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OpenAI Embedding Model**"
      ],
      "metadata": {
        "id": "lHDwnr2I0T2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain_openai import OpenAIEmbeddings\n",
        "# embed_fn = OpenAIEmbeddins(model=\"text-embedding-3-small\", api_key=os.getenv(\"OPENAI_API_KEY\"))"
      ],
      "metadata": {
        "id": "AX1ouTxOmutQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# embed = embed_fn.embed_query(\"How are you?\")"
      ],
      "metadata": {
        "id": "bYUknn1gqc9P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}